<!DOCTYPE NETSCAPE-Bookmark-file-1>

<meta http-equiv='Content-Type' content='text/html; charset=UTF-8' />
<title>Bookmarks</title>
<h1>Bookmarks</h1>

<dl><p>

<dl><dt><h3>Bookmarks bar</h3>
<dl><p><dt><a href="https://docs.google.com/document/d/1CvAClvFfyA5R-PhYUmn5OOQtYMH4h6I0nSsKchNAySU/preview">Trace Event Format - Google Docs</a>
<dt><a href="http://ruder.io/multi-task/">An Overview of Multi-Task Learning for Deep Learning</a>
<dt><a href="https://github.com/uber/horovod#usage">GitHub - uber/horovod: Distributed training framework for TensorFlow.</a>
<dt><h3>gpu</h3>
<dl><p><dt><a href="http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/">A Full Hardware Guide to Deep Learning - Tim Dettmers</a>
<dt><a href="http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/">Which GPU(s) to Get for Deep Learning</a>
</dl><p>
<dt><h3>tf</h3>
<dl><p><dt><a href="https://github.com/tensorflow/tensorflow/issues/12519">Bug on the gradients graph computation - C++ API &#xb7; Issue #12519 &#xb7; tensorflow/tensorflow &#xb7; GitHub</a>
<dt><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto">tensorflow/config.proto at master &#xb7; tensorflow/tensorflow</a>
<dt><a href="https://stackoverflow.com/questions/34706950/how-many-processes-does-tensorflow-open">How many processes does TensorFlow open? - Stack Overflow</a>
</dl><p>
<dt><h3>amd</h3>
<dl><p><dt><a href="http://www.hsafoundation.com/html_spec111/HSA_Library.htm">Welcome to the HSA Specification Library</a>
<dt><a href="https://instinct.radeon.com/en/the-potential-disruptiveness-of-amds-open-source-deep-learning-strategy/">The Potential Disruptiveness of AMD&#x2019;s Open Source Deep Learning Strategy</a>
<dt><a href="https://medium.com/intuitionmachine/amds-open-source-deep-learning-strategy-14c228be6248">AMD&#x2019;s Open Source Deep Learning Strategy &#x2013; Intuition Machine &#x2013; Medium</a>
<dt><a href="https://rocmsoftwareplatform.github.io/MIOpen/doc/html/releasenotes.html">MIOpen Release notes &#x2014; MIOpen: AMD&#39;s deep learning library</a>
<dt><a href="https://rocm.github.io/optimize_dispatch.html">ROCm, A New Era in Open GPU Computing</a>
<dt><a href="https://github.com/ROCm-Developer-Tools/LLVM-AMDGPU-Assembler-Extra">GitHub - ROCm-Developer-Tools/LLVM-AMDGPU-Assembler-Extra: LLVM AMDGPU Assembler Helper Tools</a>
<dt><a href="http://pact2016.pactconf.org/files/2016/09/PACT_HSAArch_Updates.pdf">Slide 1</a>
<dt><a href="https://rocm.github.io/languages.html">ROCm Languages</a>
<dt><a href="https://github.com/RadeonOpenCompute/hcc/blob/clang_tot_upgrade/doc/markdown/hcc_profile.md">hcc/hcc_profile.md at clang_tot_upgrade &#xb7; RadeonOpenCompute/hcc</a>
</dl><p>
<dt><h3>dbg</h3>
<dl><p><dt><a href="https://stackoverflow.com/questions/33746071/tensorflow-core-debug-missing-debug-symbols">bazel - TensorFlow core debug; missing debug symbols - Stack Overflow</a>
<dt><a href="https://stackoverflow.com/questions/6681271/debugging-a-shared-library-wrapped-by-swig-in-perl">c++ - debugging a shared library wrapped by SWIG in perl - Stack Overflow</a>
<dt><a href="https://stackoverflow.com/questions/40520146/tensorflow-doesnt-build-with-debug-mode">gcc - TensorFlow doesnt build with debug mode - Stack Overflow</a>
<dt><a href="https://gist.github.com/Mistobaan/738e76c3a5bb1f9bcc52e2809a23a7a1">Tensorflow Internals Debugging Techniques &#xb7; GitHub</a>
<dt><a href="https://www.tensorflow.org/programmers_guide/debugger">Debugging TensorFlow Programs &#xa0;|&#xa0; TensorFlow</a>
<dt><a href="https://stackoverflow.com/questions/36399337/debugging-tensorflows-c-code-behind-the-swig-interface">debugging Tensorflow&#39;s C++ code behind the SWIG interface - Stack Overflow</a>
</dl><p>
<dt><a href="https://stackoverflow.com/questions/47416445/tensorflow-execution-on-a-single-multi-core-cpu-device">threadpool - TensorFlow Execution on a single (multi-core) CPU Device - Stack Overflow</a>
<dt><a href="https://bitbucket.org/eigen/eigen/pull-requests/303/make-the-non-blocking-threadpool-more/diff">eigen / eigen / Pull request #303: Make the non-blocking threadpool more flexible and less wasteful of CPU cycles for high-latency use-cases. &#x2014; Bitbucket</a>
<dt><a href="https://stackoverflow.com/questions/34419645/asynchronous-computation-in-tensorflow">python - Asynchronous computation in TensorFlow - Stack Overflow</a>
<dt><a href="https://ebookcentral.proquest.com/lib/polymtl-ebooks/reader.action?docID=4179010">ProQuest Ebook Central Reader</a>
<dt><a href="http://rocm-documentation.readthedocs.io/en/latest/Tutorial/Tutorial.html">Tutorial &#x2014; ROCm Documentation latest documentation</a>
<dt><a href="https://github.com/tensorflow/tensorflow/issues/1824">Profiling tools for open source TensorFlow &#xb7; Issue #1824 &#xb7; tensorflow/tensorflow &#xb7; GitHub</a>
<dt><a href="https://github.com/tensorflow/tensorflow/issues/492">memory issues &#xb7; Issue #492 &#xb7; tensorflow/tensorflow &#xb7; GitHub</a>
<dt><a href="https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network">python - What is batch size in neural network? - Cross Validated</a>
<dt><a href="https://datascience.stackexchange.com/questions/12649/how-to-calculate-the-mini-batch-memory-impact-when-training-deep-learning-models">tensorflow - How to calculate the mini-batch memory impact when training deep learning models? - Data Science Stack Exchange</a>
<dt><a href="https://stackoverflow.com/questions/42307975/memory-management-when-using-gpu-in-tensorflow">Memory management when using GPU in TensorFlow - Stack Overflow</a>
<dt><a href="http://rocm-documentation.readthedocs.io/en/latest/index.html">Welcome to ROCm Platform &#x2014; ROCm Documentation latest documentation</a>
<dt><a href="https://stackoverflow.com/questions/37732196/tensorflow-difference-between-multi-gpus-and-distributed-tensorflow">deep learning - tensorflow: difference between multi GPUs and distributed tensorflow - Stack Overflow</a>
<dt><a href="https://stackoverflow.com/questions/43147435/how-does-asynchronous-training-work-in-distributed-tensorflow">python - How does asynchronous training work in distributed Tensorflow? - Stack Overflow</a>
<dt><a href="https://github.com/tensorflow/tensorflow/blob/6b1d4fd8090d44d20fdadabf06f1a9b178c3d80c/tensorflow/python/tools/graph_metrics.py">tensorflow/graph_metrics.py at 6b1d4fd8090d44d20fdadabf06f1a9b178c3d80c &#xb7; tensorflow/tensorflow &#xb7; GitHub</a>
<dt><a href="https://github.com/tensorflow/tensorflow/issues/4359#issuecomment-269241038">Feature Request: plug-in support for new devices &#xb7; Issue #4359 &#xb7; tensorflow/tensorflow &#xb7; GitHub</a>
<dt><a href="https://medium.com/@yaroslavvb/fitting-larger-networks-into-memory-583e3c758ff9">Fitting larger networks into memory. &#x2013; Yaroslav Bulatov &#x2013; Medium</a>
<dt><a href="https://rocmsoftwareplatform.github.io/MIOpen/doc/html/convolution.html">Convolutional Layer &#x2014; MIOpen: AMD&#39;s deep learning library</a>
<dt><a href="https://stackoverflow.com/questions/43150671/can-single-cpu-core-work-with-multiple-clients-using-distributed-tensorflow">Can single CPU core work with multiple clients using Distributed Tensorflow? - Stack Overflow</a>
<dt><a href="https://grpc.io/docs/guides/concepts.html">grpc / gRPC Concepts</a>
<dt><a href="https://github.com/tensorflow/tensorflow/issues/2916">[Feature] RDMA support for distribued Tensorflow &#xb7; Issue #2916 &#xb7; tensorflow/tensorflow</a>
</dl><p>
</dl>

<dl><dt><h3>Other bookmarks</h3>
<dl><p></dl><p>
</dl>
